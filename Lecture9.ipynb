{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Margaret Atwood\n",
    ":class: tip\n",
    "Every aspect of human technology has a dark side, including the bow and arrow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÖ Build your own model \n",
    "\n",
    "You have been assigned one dataset from [MatBench](https://matbench.materialsproject.org) as introduced in the [Lecture slides](https://speakerdeck.com/aronwalsh/mlformaterials-lecture9-challenge). You are free to choose and tune any machine-learning model, with any Python library, but it should be appropriate for the problem. For instance, [XGBoost](https://xgboost.readthedocs.io) could be a good starting starting point to build a regression model. You can refer back to earlier notebooks and repurpose code as needed. \n",
    "\n",
    "You may reach the limits of computing processing power on Google Colab. Building a useful model with limited resources is a real-world skill. Using other free resources is allowed if you find an alternative service, as is running on your own computer. A model tracker such as [wandb](https://wandb.ai) could be helpful for advanced users. If you want to try a brute force approach, a library such as [Automatminer](https://hackingmaterials.lbl.gov/automatminer) may be of interest.\n",
    "\n",
    "This notebook should be used for keeping a record of your model development, submission, and even your presentation. You are free to edit (add/remove/delete) or rearrange the cells as you see fit.\n",
    "\n",
    "### Your details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the work of Abhi Rajendran [CID: 1712516]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Insert your values\n",
    "Name = \"Abhi Rajendran\" # Replace with your name\n",
    "CID = 1712516 # Replace with your College ID (as a numeric value with no leading 0s)\n",
    "\n",
    "# Set a random seed using the CID value\n",
    "CID = int(CID)\n",
    "np.random.seed(CID)\n",
    "\n",
    "# Print the message\n",
    "print(\"This is the work of \" + Name + \" [CID: \" + str(CID) + \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "You have been assigned one dataset from the [list](https://matbench.materialsproject.org/Benchmark%20Info/matbench_v0.1/) on [MatBench](https://matbench.materialsproject.org). You should state what problem you are trying to solve and comment on the best-performing model in the benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spare cell\n",
    "\n",
    "#Performing classification on glasses - gfa: Target variable. Glass forming ability: 1 means glass forming and corresponds to amorphous, 0 means non full glass forming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "Check the data distribution and apply appropriate pre-processing steps as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: matbench_glass\n",
      "Description: Matbench v0.1 test dataset for predicting full bulk metallic glass formation ability from chemical formula. Retrieved from \"Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys,‚Äô a volume of the Landolt‚Äì B√∂rnstein collection. Deduplicated according to composition, ensuring no compositions were reported as both GFA and not GFA (i.e., all reports agreed on the classification designation). For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.\n",
      "Columns:\n",
      "\tcomposition: Chemical formula.\n",
      "\tgfa: Target variable. Glass forming ability: 1 means glass forming and corresponds to amorphous, 0 means non full glass forming.\n",
      "Num Entries: 5680\n",
      "Reference: Y. Kawazoe, T. Masumoto, A.-P. Tsai, J.-Z. Yu, T. Aihara Jr. (1997) Y. Kawazoe, J.-Z. Yu, A.-P. Tsai, T. Masumoto (ed.) SpringerMaterials\n",
      "Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys ¬∑ 1 Introduction Landolt-B√∂rnstein - Group III Condensed Matter 37A (Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys) https://www.springer.com/gp/book/9783540605072 (Springer-Verlag Berlin Heidelberg ¬© 1997) Accessed: 03-09-2019\n",
      "Bibtex citations: [\"@Article{Dunn2020,\\nauthor={Dunn, Alexander\\nand Wang, Qi\\nand Ganose, Alex\\nand Dopp, Daniel\\nand Jain, Anubhav},\\ntitle={Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm},\\njournal={npj Computational Materials},\\nyear={2020},\\nmonth={Sep},\\nday={15},\\nvolume={6},\\nnumber={1},\\npages={138},\\nabstract={We present a benchmark test suite and an automated machine learning procedure for evaluating supervised machine learning (ML) models for predicting properties of inorganic bulk materials. The test suite, Matbench, is a set of 13{\\\\thinspace}ML tasks that range in size from 312 to 132k samples and contain data from 10 density functional theory-derived and experimental sources. Tasks include predicting optical, thermal, electronic, thermodynamic, tensile, and elastic properties given a material's composition and/or crystal structure. The reference algorithm, Automatminer, is a highly-extensible, fully automated ML pipeline for predicting materials properties from materials primitives (such as composition and crystal structure) without user intervention or hyperparameter tuning. We test Automatminer on the Matbench test suite and compare its predictive power with state-of-the-art crystal graph neural networks and a traditional descriptor-based Random Forest model. We find Automatminer achieves the best performance on 8 of 13 tasks in the benchmark. We also show our test suite is capable of exposing predictive advantages of each algorithm---namely, that crystal graph methods appear to outperform traditional machine learning methods given {\\\\textasciitilde}104 or greater data points. We encourage evaluating materials ML algorithms on the Matbench benchmark and comparing them against the latest version of Automatminer.},\\nissn={2057-3960},\\ndoi={10.1038/s41524-020-00406-3},\\nurl={https://doi.org/10.1038/s41524-020-00406-3}\\n}\\n\", '@Misc{LandoltBornstein1997:sm_lbs_978-3-540-47679-5_2,\\nauthor=\"Kawazoe, Y.\\nand Masumoto, T.\\nand Tsai, A.-P.\\nand Yu, J.-Z.\\nand Aihara Jr., T.\",\\neditor=\"Kawazoe, Y.\\nand Yu, J.-Z.\\nand Tsai, A.-P.\\nand Masumoto, T.\",\\ntitle=\"Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys {\\\\textperiodcentered} 1 Introduction: Datasheet from Landolt-B{\\\\\"o}rnstein - Group III Condensed Matter {\\\\textperiodcentered} Volume 37A: ``Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys\\'\\' in SpringerMaterials (https://dx.doi.org/10.1007/10510374{\\\\_}2)\",\\npublisher=\"Springer-Verlag Berlin Heidelberg\",\\nnote=\"Copyright 1997 Springer-Verlag Berlin Heidelberg\",\\nnote=\"Part of SpringerMaterials\",\\nnote=\"accessed 2018-10-23\",\\ndoi=\"10.1007/10510374_2\",\\nurl=\"https://materials.springer.com/lb/docs/sm_lbs_978-3-540-47679-5_2\"\\n}', '@Article{Ward2016,\\nauthor={Ward, Logan\\nand Agrawal, Ankit\\nand Choudhary, Alok\\nand Wolverton, Christopher},\\ntitle={A general-purpose machine learning framework for predicting properties of inorganic materials},\\njournal={Npj Computational Materials},\\nyear={2016},\\nmonth={Aug},\\nday={26},\\npublisher={The Author(s)},\\nvolume={2},\\npages={16028},\\nnote={Article},\\nurl={http://dx.doi.org/10.1038/npjcompumats.2016.28}\\n}']\n",
      "File type: json.gz\n",
      "Figshare URL: https://ml.materialsproject.org/projects/matbench_glass.json.gz\n",
      "SHA256 Hash Digest: 36beb654e2a463ee2a6572105bea0ca2961eee7c7b26a25377bff2c3b338e53a\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get dataset info from matminer\n",
    "from matminer.datasets import get_all_dataset_info\n",
    "from matminer.datasets import load_dataset\n",
    "\n",
    "  # D (GTA - Yifan)\n",
    "info = get_all_dataset_info(\"matbench_glass\")\n",
    "\n",
    "# Check out the info about the dataset.\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading file /opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/matminer/datasets/matbench_glass.json.gz: 0it [00:00, ?it/s]0, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>composition</th>\n",
       "      <th>gfa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al(NiB)2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al10Co21B19</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al10Co23B17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al10Co27B13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>ZrTi9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>ZrTiSi2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>ZrTiSi3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>ZrVCo8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>ZrVNi2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5680 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      composition    gfa\n",
       "0              Al  False\n",
       "1        Al(NiB)2   True\n",
       "2     Al10Co21B19   True\n",
       "3     Al10Co23B17   True\n",
       "4     Al10Co27B13   True\n",
       "...           ...    ...\n",
       "5675        ZrTi9  False\n",
       "5676      ZrTiSi2   True\n",
       "5677      ZrTiSi3   True\n",
       "5678       ZrVCo8   True\n",
       "5679       ZrVNi2   True\n",
       "\n",
       "[5680 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# module imports \n",
    "import numpy as np  # Numerical operations\n",
    "import pandas as pd  # Data manipulation with DataFrames\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "import seaborn as sns  # Statistical visualisation\n",
    "\n",
    "# Load dataset into a pandas DataFrame\n",
    "df = load_dataset(\"matbench_glass\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>composition</th>\n",
       "      <th>gfa</th>\n",
       "      <th>composition_pmg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5680</td>\n",
       "      <td>5680</td>\n",
       "      <td>5680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5680</td>\n",
       "      <td>2</td>\n",
       "      <td>5680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Al</td>\n",
       "      <td>True</td>\n",
       "      <td>(Al)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>4035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       composition   gfa composition_pmg\n",
       "count         5680  5680            5680\n",
       "unique        5680     2            5680\n",
       "top             Al  True            (Al)\n",
       "freq             1  4035               1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ElementProperty:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3624/5680 [00:07<00:04, 500.32it/s]"
     ]
    }
   ],
   "source": [
    "from matminer.featurizers.composition.composite import ElementProperty\n",
    "from pymatgen.core import Composition\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, embedding=\"magpie\"):\n",
    "        self.embedding = embedding\n",
    "        self.featuriser = ElementProperty.from_preset(preset_name='magpie')\n",
    "        self.featuriser.set_n_jobs(1)\n",
    "    \n",
    "    def featurise_composition(self, df):\n",
    "        # Create a copy of the dataframe\n",
    "        data = df.copy()\n",
    "        print(f\"Using {self.embedding} embedding for composition featurisation.\")\n",
    "        \n",
    "        onehot_df = composition_featuriser(data[\"composition\"], embedding=self.embedding, stats=[\"sum\"])\n",
    "        onehot_df.drop(columns=['formula'], inplace=True)  # Drop the original composition column\n",
    "        \n",
    "        return onehot_df\n",
    "    \n",
    "    def featurise_with_pymatgen(self, df, col_id='composition'):\n",
    "        df[\"composition_pmg\"] = df[col_id].map(Composition)\n",
    "        df_pmg = self.featuriser.featurize_dataframe(df, col_id='composition_pmg')\n",
    "        return df_pmg\n",
    "    \n",
    "    def scale_data(self, df):\n",
    "        # Create a copy of the dataframe\n",
    "        data = df.copy()\n",
    "        \n",
    "        # Scale only columns that are numerical \n",
    "        numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        print(f\"Scaling the following columns: {numerical_cols}\")\n",
    "\n",
    "        # Scale numerical columns\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(data[numerical_cols])\n",
    "        \n",
    "        # Convert the scaled data back to a DataFrame\n",
    "        #scaled_df = pd.DataFrame(scaled_data, columns=numerical_cols, index=data.index)\n",
    "        \n",
    "        return scaled_data\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Create an instance of the DataProcessor class\n",
    "data_processor = DataProcessor(embedding=\"magpie\")\n",
    "\n",
    "# Featurise the composition\n",
    "featurised_data = data_processor.featurise_with_pymatgen(df)\n",
    "\n",
    "# Scale the featurised data\n",
    "scaled_data = data_processor.scale_data(featurised_data)\n",
    "\n",
    "# Create a copy of the scaled data for further processing\n",
    "#processed_data = scaled_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MagpieData minimum Number</th>\n",
       "      <th>MagpieData maximum Number</th>\n",
       "      <th>MagpieData range Number</th>\n",
       "      <th>MagpieData mean Number</th>\n",
       "      <th>MagpieData avg_dev Number</th>\n",
       "      <th>MagpieData mode Number</th>\n",
       "      <th>MagpieData minimum MendeleevNumber</th>\n",
       "      <th>MagpieData maximum MendeleevNumber</th>\n",
       "      <th>MagpieData range MendeleevNumber</th>\n",
       "      <th>MagpieData mean MendeleevNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>MagpieData range GSmagmom</th>\n",
       "      <th>MagpieData mean GSmagmom</th>\n",
       "      <th>MagpieData avg_dev GSmagmom</th>\n",
       "      <th>MagpieData mode GSmagmom</th>\n",
       "      <th>MagpieData minimum SpaceGroupNumber</th>\n",
       "      <th>MagpieData maximum SpaceGroupNumber</th>\n",
       "      <th>MagpieData range SpaceGroupNumber</th>\n",
       "      <th>MagpieData mean SpaceGroupNumber</th>\n",
       "      <th>MagpieData avg_dev SpaceGroupNumber</th>\n",
       "      <th>MagpieData mode SpaceGroupNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991111</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.294872</td>\n",
       "      <td>0.115235</td>\n",
       "      <td>0.299240</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.179104</td>\n",
       "      <td>0.864751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282089</td>\n",
       "      <td>0.118423</td>\n",
       "      <td>0.270805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.728889</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.259912</td>\n",
       "      <td>0.707386</td>\n",
       "      <td>0.275832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.115839</td>\n",
       "      <td>0.287417</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.841452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733642</td>\n",
       "      <td>0.323387</td>\n",
       "      <td>0.714861</td>\n",
       "      <td>0.733642</td>\n",
       "      <td>0.728889</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.259912</td>\n",
       "      <td>0.580480</td>\n",
       "      <td>0.174397</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.129120</td>\n",
       "      <td>0.289968</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.832636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733642</td>\n",
       "      <td>0.354186</td>\n",
       "      <td>0.728947</td>\n",
       "      <td>0.733642</td>\n",
       "      <td>0.728889</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.259912</td>\n",
       "      <td>0.592484</td>\n",
       "      <td>0.163458</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.155684</td>\n",
       "      <td>0.282119</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.815004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733642</td>\n",
       "      <td>0.415783</td>\n",
       "      <td>0.728947</td>\n",
       "      <td>0.733642</td>\n",
       "      <td>0.728889</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.259912</td>\n",
       "      <td>0.616494</td>\n",
       "      <td>0.136342</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.235979</td>\n",
       "      <td>0.099338</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.216358</td>\n",
       "      <td>0.268273</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.753764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.145374</td>\n",
       "      <td>0.804924</td>\n",
       "      <td>0.160707</td>\n",
       "      <td>0.968254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.250184</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.808077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.145374</td>\n",
       "      <td>0.840295</td>\n",
       "      <td>0.154279</td>\n",
       "      <td>0.968254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.297860</td>\n",
       "      <td>0.074197</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.669541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733642</td>\n",
       "      <td>0.615975</td>\n",
       "      <td>0.469531</td>\n",
       "      <td>0.733642</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154185</td>\n",
       "      <td>0.665584</td>\n",
       "      <td>0.061361</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.325782</td>\n",
       "      <td>0.157131</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>0.631758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282089</td>\n",
       "      <td>0.148028</td>\n",
       "      <td>0.282089</td>\n",
       "      <td>0.282089</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154185</td>\n",
       "      <td>0.887992</td>\n",
       "      <td>0.118095</td>\n",
       "      <td>0.936508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5680 rows √ó 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MagpieData minimum Number  MagpieData maximum Number  \\\n",
       "0                      0.150000                     0.0125   \n",
       "1                      0.016667                     0.2000   \n",
       "2                      0.016667                     0.1875   \n",
       "3                      0.016667                     0.1875   \n",
       "4                      0.016667                     0.1875   \n",
       "...                         ...                        ...   \n",
       "5675                   0.300000                     0.3500   \n",
       "5676                   0.166667                     0.3500   \n",
       "5677                   0.166667                     0.3500   \n",
       "5678                   0.316667                     0.3500   \n",
       "5679                   0.316667                     0.3500   \n",
       "\n",
       "      MagpieData range Number  MagpieData mean Number  \\\n",
       "0                    0.000000                0.072975   \n",
       "1                    0.294872                0.115235   \n",
       "2                    0.282051                0.115839   \n",
       "3                    0.282051                0.129120   \n",
       "4                    0.282051                0.155684   \n",
       "...                       ...                     ...   \n",
       "5675                 0.230769                0.235979   \n",
       "5676                 0.333333                0.216358   \n",
       "5677                 0.333333                0.190700   \n",
       "5678                 0.217949                0.297860   \n",
       "5679                 0.217949                0.325782   \n",
       "\n",
       "      MagpieData avg_dev Number  MagpieData mode Number  \\\n",
       "0                      0.000000                0.120000   \n",
       "1                      0.299240                0.013333   \n",
       "2                      0.287417                0.306667   \n",
       "3                      0.289968                0.306667   \n",
       "4                      0.282119                0.306667   \n",
       "...                         ...                     ...   \n",
       "5675                   0.099338                0.240000   \n",
       "5676                   0.268273                0.133333   \n",
       "5677                   0.250184                0.133333   \n",
       "5678                   0.074197                0.306667   \n",
       "5679                   0.157131                0.320000   \n",
       "\n",
       "      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber  \\\n",
       "0                               1.000000                                0.60   \n",
       "1                               0.818182                                0.60   \n",
       "2                               0.772727                                0.60   \n",
       "3                               0.772727                                0.60   \n",
       "4                               0.772727                                0.60   \n",
       "...                                  ...                                 ...   \n",
       "5675                            0.545455                                0.02   \n",
       "5676                            0.545455                                0.70   \n",
       "5677                            0.545455                                0.70   \n",
       "5678                            0.560606                                0.30   \n",
       "5679                            0.560606                                0.36   \n",
       "\n",
       "      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...  \\\n",
       "0                             0.000000                         0.946614  ...   \n",
       "1                             0.179104                         0.864751  ...   \n",
       "2                             0.223881                         0.841452  ...   \n",
       "3                             0.223881                         0.832636  ...   \n",
       "4                             0.223881                         0.815004  ...   \n",
       "...                                ...                              ...  ...   \n",
       "5675                          0.014925                         0.475904  ...   \n",
       "5676                          0.522388                         0.753764  ...   \n",
       "5677                          0.522388                         0.808077  ...   \n",
       "5678                          0.208955                         0.669541  ...   \n",
       "5679                          0.253731                         0.631758  ...   \n",
       "\n",
       "      MagpieData range GSmagmom  MagpieData mean GSmagmom  \\\n",
       "0                      0.000000                  0.000000   \n",
       "1                      0.282089                  0.118423   \n",
       "2                      0.733642                  0.323387   \n",
       "3                      0.733642                  0.354186   \n",
       "4                      0.733642                  0.415783   \n",
       "...                         ...                       ...   \n",
       "5675                   0.000011                  0.000010   \n",
       "5676                   0.000011                  0.000003   \n",
       "5677                   0.000011                  0.000002   \n",
       "5678                   0.733642                  0.615975   \n",
       "5679                   0.282089                  0.148028   \n",
       "\n",
       "      MagpieData avg_dev GSmagmom  MagpieData mode GSmagmom  \\\n",
       "0                        0.000000                  0.000000   \n",
       "1                        0.270805                  0.000000   \n",
       "2                        0.714861                  0.733642   \n",
       "3                        0.728947                  0.733642   \n",
       "4                        0.728947                  0.733642   \n",
       "...                           ...                       ...   \n",
       "5675                     0.000004                  0.000011   \n",
       "5676                     0.000008                  0.000000   \n",
       "5677                     0.000007                  0.000000   \n",
       "5678                     0.469531                  0.733642   \n",
       "5679                     0.282089                  0.282089   \n",
       "\n",
       "      MagpieData minimum SpaceGroupNumber  \\\n",
       "0                                0.991111   \n",
       "1                                0.728889   \n",
       "2                                0.728889   \n",
       "3                                0.728889   \n",
       "4                                0.728889   \n",
       "...                                   ...   \n",
       "5675                             0.853333   \n",
       "5676                             0.853333   \n",
       "5677                             0.853333   \n",
       "5678                             0.853333   \n",
       "5679                             0.853333   \n",
       "\n",
       "      MagpieData maximum SpaceGroupNumber  MagpieData range SpaceGroupNumber  \\\n",
       "0                                0.885714                           0.000000   \n",
       "1                                0.885714                           0.259912   \n",
       "2                                0.885714                           0.259912   \n",
       "3                                0.885714                           0.259912   \n",
       "4                                0.885714                           0.259912   \n",
       "...                                   ...                                ...   \n",
       "5675                             0.000000                           0.000000   \n",
       "5676                             0.942857                           0.145374   \n",
       "5677                             0.942857                           0.145374   \n",
       "5678                             1.000000                           0.154185   \n",
       "5679                             1.000000                           0.154185   \n",
       "\n",
       "      MagpieData mean SpaceGroupNumber  MagpieData avg_dev SpaceGroupNumber  \\\n",
       "0                             0.960342                             0.000000   \n",
       "1                             0.707386                             0.275832   \n",
       "2                             0.580480                             0.174397   \n",
       "3                             0.592484                             0.163458   \n",
       "4                             0.616494                             0.136342   \n",
       "...                                ...                                  ...   \n",
       "5675                          0.628069                             0.000000   \n",
       "5676                          0.804924                             0.160707   \n",
       "5677                          0.840295                             0.154279   \n",
       "5678                          0.665584                             0.061361   \n",
       "5679                          0.887992                             0.118095   \n",
       "\n",
       "      MagpieData mode SpaceGroupNumber  \n",
       "0                             0.936508  \n",
       "1                             0.000000  \n",
       "2                             0.444444  \n",
       "3                             0.444444  \n",
       "4                             0.444444  \n",
       "...                                ...  \n",
       "5675                          0.444444  \n",
       "5676                          0.968254  \n",
       "5677                          0.968254  \n",
       "5678                          0.444444  \n",
       "5679                          0.936508  \n",
       "\n",
       "[5680 rows x 132 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_Number</th>\n",
       "      <th>sum_MendeleevNumber</th>\n",
       "      <th>sum_AtomicWeight</th>\n",
       "      <th>sum_MeltingT</th>\n",
       "      <th>sum_Column</th>\n",
       "      <th>sum_Row</th>\n",
       "      <th>sum_CovalentRadius</th>\n",
       "      <th>sum_Electronegativity</th>\n",
       "      <th>sum_NsValence</th>\n",
       "      <th>sum_NpValence</th>\n",
       "      <th>...</th>\n",
       "      <th>sum_NValence</th>\n",
       "      <th>sum_NsUnfilled</th>\n",
       "      <th>sum_NpUnfilled</th>\n",
       "      <th>sum_NdUnfilled</th>\n",
       "      <th>sum_NfUnfilled</th>\n",
       "      <th>sum_NUnfilled</th>\n",
       "      <th>sum_GSvolume_pa</th>\n",
       "      <th>sum_GSbandgap</th>\n",
       "      <th>sum_GSmagmom</th>\n",
       "      <th>sum_SpaceGroupNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009017</td>\n",
       "      <td>0.012245</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.015103</td>\n",
       "      <td>0.013299</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014307</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>5.921133e-03</td>\n",
       "      <td>0.011407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.104978</td>\n",
       "      <td>0.135399</td>\n",
       "      <td>0.091260</td>\n",
       "      <td>0.166802</td>\n",
       "      <td>0.131591</td>\n",
       "      <td>0.152352</td>\n",
       "      <td>0.147976</td>\n",
       "      <td>0.157029</td>\n",
       "      <td>0.155063</td>\n",
       "      <td>0.048013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120033</td>\n",
       "      <td>0.080051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>0.124037</td>\n",
       "      <td>1.616934e-01</td>\n",
       "      <td>0.130265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.134241</td>\n",
       "      <td>0.096462</td>\n",
       "      <td>0.164656</td>\n",
       "      <td>0.129725</td>\n",
       "      <td>0.156442</td>\n",
       "      <td>0.150308</td>\n",
       "      <td>0.156488</td>\n",
       "      <td>0.155063</td>\n",
       "      <td>0.044702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111755</td>\n",
       "      <td>0.087675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153614</td>\n",
       "      <td>0.078660</td>\n",
       "      <td>0.110981</td>\n",
       "      <td>1.770928e-01</td>\n",
       "      <td>0.131051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122744</td>\n",
       "      <td>0.131924</td>\n",
       "      <td>0.106865</td>\n",
       "      <td>0.160363</td>\n",
       "      <td>0.125992</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.154971</td>\n",
       "      <td>0.155408</td>\n",
       "      <td>0.155063</td>\n",
       "      <td>0.038079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095199</td>\n",
       "      <td>0.102922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147590</td>\n",
       "      <td>0.080548</td>\n",
       "      <td>0.084868</td>\n",
       "      <td>2.078915e-01</td>\n",
       "      <td>0.132622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>0.030417</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>0.026901</td>\n",
       "      <td>0.034551</td>\n",
       "      <td>0.008866</td>\n",
       "      <td>0.038855</td>\n",
       "      <td>0.041470</td>\n",
       "      <td>0.023429</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>0.025061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008412e-06</td>\n",
       "      <td>0.024498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>0.009240</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.009047</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.020330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>1.120457e-07</td>\n",
       "      <td>0.009092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>0.012382</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.010758</td>\n",
       "      <td>0.015185</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.015183</td>\n",
       "      <td>0.012254</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.020330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021084</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>1.120457e-07</td>\n",
       "      <td>0.012277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>0.035935</td>\n",
       "      <td>0.021139</td>\n",
       "      <td>0.031852</td>\n",
       "      <td>0.032438</td>\n",
       "      <td>0.018432</td>\n",
       "      <td>0.038855</td>\n",
       "      <td>0.033726</td>\n",
       "      <td>0.028172</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029367</td>\n",
       "      <td>0.016576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.159749e-02</td>\n",
       "      <td>0.024989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>0.014401</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>0.012715</td>\n",
       "      <td>0.012663</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.014315</td>\n",
       "      <td>0.012630</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014307</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.921133e-03</td>\n",
       "      <td>0.009527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5680 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sum_Number  sum_MendeleevNumber  sum_AtomicWeight  sum_MeltingT  \\\n",
       "0       0.000135             0.001241          0.000145      0.000019   \n",
       "1       0.009017             0.012245          0.007658      0.015103   \n",
       "2       0.104978             0.135399          0.091260      0.166802   \n",
       "3       0.110900             0.134241          0.096462      0.164656   \n",
       "4       0.122744             0.131924          0.106865      0.160363   \n",
       "...          ...                  ...               ...           ...   \n",
       "5675    0.030417             0.016051          0.026901      0.034551   \n",
       "5676    0.010498             0.008274          0.009240      0.012064   \n",
       "5677    0.012382             0.011500          0.010758      0.015185   \n",
       "5678    0.035935             0.021139          0.031852      0.032438   \n",
       "5679    0.014401             0.006991          0.012715      0.012663   \n",
       "\n",
       "      sum_Column   sum_Row  sum_CovalentRadius  sum_Electronegativity  \\\n",
       "0       0.002566  0.000000            0.000000               0.000506   \n",
       "1       0.013299  0.012270            0.011547               0.013841   \n",
       "2       0.131591  0.152352            0.147976               0.157029   \n",
       "3       0.129725  0.156442            0.150308               0.156488   \n",
       "4       0.125992  0.164622            0.154971               0.155408   \n",
       "...          ...       ...                 ...                    ...   \n",
       "5675    0.008866  0.038855            0.041470               0.023429   \n",
       "5676    0.007933  0.012270            0.012102               0.009047   \n",
       "5677    0.011199  0.015337            0.015183               0.012254   \n",
       "5678    0.018432  0.038855            0.033726               0.028172   \n",
       "5679    0.006300  0.014315            0.012630               0.009233   \n",
       "\n",
       "      sum_NsValence  sum_NpValence  ...  sum_NValence  sum_NsUnfilled  \\\n",
       "0          0.000000       0.001656  ...      0.000419             0.0   \n",
       "1          0.012658       0.004967  ...      0.011309             0.0   \n",
       "2          0.155063       0.048013  ...      0.114764             0.0   \n",
       "3          0.155063       0.044702  ...      0.119791             0.0   \n",
       "4          0.155063       0.038079  ...      0.129843             0.0   \n",
       "...             ...            ...  ...           ...             ...   \n",
       "5675       0.028481       0.000000  ...      0.015916             0.0   \n",
       "5676       0.009494       0.006623  ...      0.005864             0.0   \n",
       "5677       0.012658       0.009934  ...      0.007539             0.0   \n",
       "5678       0.028481       0.000000  ...      0.033089             0.0   \n",
       "5679       0.009494       0.000000  ...      0.011309             0.0   \n",
       "\n",
       "      sum_NpUnfilled  sum_NdUnfilled  sum_NfUnfilled  sum_NUnfilled  \\\n",
       "0           0.004139        0.000000             0.0       0.003765   \n",
       "1           0.012417        0.005083             0.0       0.014307   \n",
       "2           0.120033        0.080051             0.0       0.156627   \n",
       "3           0.111755        0.087675             0.0       0.153614   \n",
       "4           0.095199        0.102922             0.0       0.147590   \n",
       "...              ...             ...             ...            ...   \n",
       "5675        0.000000        0.101652             0.0       0.060241   \n",
       "5676        0.006623        0.020330             0.0       0.018072   \n",
       "5677        0.009934        0.020330             0.0       0.021084   \n",
       "5678        0.000000        0.049555             0.0       0.029367   \n",
       "5679        0.000000        0.024142             0.0       0.014307   \n",
       "\n",
       "      sum_GSvolume_pa  sum_GSbandgap  sum_GSmagmom  sum_SpaceGroupNumber  \n",
       "0            0.000958       0.000000  0.000000e+00              0.000435  \n",
       "1            0.006331       0.013057  5.921133e-03              0.011407  \n",
       "2            0.077716       0.124037  1.616934e-01              0.130265  \n",
       "3            0.078660       0.110981  1.770928e-01              0.131051  \n",
       "4            0.080548       0.084868  2.078915e-01              0.132622  \n",
       "...               ...            ...           ...                   ...  \n",
       "5675         0.025061       0.000000  1.008412e-06              0.024498  \n",
       "5676         0.010832       0.006623  1.120457e-07              0.009092  \n",
       "5677         0.013971       0.009934  1.120457e-07              0.012277  \n",
       "5678         0.016576       0.000000  6.159749e-02              0.024989  \n",
       "5679         0.007158       0.000000  5.921133e-03              0.009527  \n",
       "\n",
       "[5680 rows x 22 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5680, 133)\n"
     ]
    }
   ],
   "source": [
    "processed_data = df_pmg.copy()\n",
    "combined_data = processed_data.drop(columns=[\"composition\", \"composition_pmg\"])\n",
    "#print shape of combined_data\n",
    "print(combined_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those with a larger dataset, you could hit some resource limits such as not enough memory. Here is an approach to reduce the computational burden:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice \n",
    "\n",
    "Define your model and justify your choice based on the problem and available data. You can look back at earlier notebooks and investigate other examples online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.753521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.706866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.901408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.830106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.861796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.896127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  accuracy\n",
       "0      LogisticRegression  0.753521\n",
       "1                     SVC  0.706866\n",
       "2  RandomForestClassifier  0.901408\n",
       "3    KNeighborsClassifier  0.830106\n",
       "4  DecisionTreeClassifier  0.861796\n",
       "5           XGBClassifier  0.896127"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of common classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create a list of models\n",
    "models = [LogisticRegression(), SVC(), RandomForestClassifier(), KNeighborsClassifier(), DecisionTreeClassifier(), XGBClassifier()]\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X = combined_data.drop(columns=[\"gfa\"])\n",
    "y = combined_data[\"gfa\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=CID)\n",
    "\n",
    "# create a function to train and evaluate the models\n",
    "def train_and_evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    results = []\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.append({\"model\": model.__class__.__name__,\n",
    "                        \"accuracy\": accuracy})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# train and evaluate the models\n",
    "results = train_and_evaluate_models(models, X_train, X_test, y_train, y_test)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "\n",
    "# plot the confusion matrix for the best model\n",
    "best_model = RandomForestClassifier()\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "plot_confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.762852</td>\n",
       "      <td>0.018934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.710387</td>\n",
       "      <td>0.005650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.891725</td>\n",
       "      <td>0.006704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.821655</td>\n",
       "      <td>0.013689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.851408</td>\n",
       "      <td>0.010787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.889261</td>\n",
       "      <td>0.006759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  mean_accuracy  std_accuracy\n",
       "0      LogisticRegression       0.762852      0.018934\n",
       "1                     SVC       0.710387      0.005650\n",
       "2  RandomForestClassifier       0.891725      0.006704\n",
       "3    KNeighborsClassifier       0.821655      0.013689\n",
       "4  DecisionTreeClassifier       0.851408      0.010787\n",
       "5           XGBClassifier       0.889261      0.006759"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# create a function to perform cross validation\n",
    "def cross_validate_models(models, X, y, cv=5):\n",
    "    results = []\n",
    "    for model in models:\n",
    "        kfold = KFold(n_splits=cv, random_state=42, shuffle=True)\n",
    "        scores = cross_val_score(model, X, y, cv=kfold)\n",
    "        results.append({\"model\": model.__class__.__name__,\n",
    "                        \"mean_accuracy\": np.mean(scores),\n",
    "                        \"std_accuracy\": np.std(scores)})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# cross validate the models\n",
    "cross_val_results = cross_validate_models(models, X, y)\n",
    "cross_val_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   2.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   2.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   5.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   5.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   3.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   3.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   7.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   5.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   3.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.9s[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.8s\n",
      "\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   3.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   3.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   3.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   4.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   3.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m rf, param_grid \u001b[38;5;241m=\u001b[39m param_grid,\n\u001b[1;32m     19\u001b[0m                             cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Fit the GridSearchCV object to the data\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Get the best parameters\u001b[39;00m\n\u001b[1;32m     25\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/glasses_classes/lib/python3.10/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning of Best Model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a parameter grid for the Random Forest Classifier\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                            cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new Random Forest Classifier with the best parameters\n",
    "best_rf = RandomForestClassifier(**best_params)\n",
    "\n",
    "# Train the model\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# roc auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"ROC AUC: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device\n",
      "Input dimension: 132\n",
      "Epoch 1/30, Training Loss: 0.7174247595625864\n",
      "Epoch 1/30, Validation Loss: 0.6320416463745965\n",
      "Epoch 2/30, Training Loss: 0.5994351548208318\n",
      "Epoch 2/30, Validation Loss: 0.5927645828988817\n",
      "Epoch 3/30, Training Loss: 0.5523978114967615\n",
      "Epoch 3/30, Validation Loss: 0.5301537778642442\n",
      "Epoch 4/30, Training Loss: 0.5287810249227873\n",
      "Epoch 4/30, Validation Loss: 0.5107074148125119\n",
      "Epoch 5/30, Training Loss: 0.5012564239367633\n",
      "Epoch 5/30, Validation Loss: 0.49097537332110935\n",
      "Epoch 6/30, Training Loss: 0.5027643710794584\n",
      "Epoch 6/30, Validation Loss: 0.4924301356077194\n",
      "Epoch 7/30, Training Loss: 0.4931478458391109\n",
      "Epoch 7/30, Validation Loss: 0.4670731872320175\n",
      "Epoch 8/30, Training Loss: 0.47842340612075696\n",
      "Epoch 8/30, Validation Loss: 0.529673405819469\n",
      "Epoch 9/30, Training Loss: 0.4868000086764215\n",
      "Epoch 9/30, Validation Loss: 0.5165393153826395\n",
      "Epoch 10/30, Training Loss: 0.47466712560452207\n",
      "Epoch 10/30, Validation Loss: 0.4571272283792496\n",
      "Epoch 11/30, Training Loss: 0.47539871679225437\n",
      "Epoch 11/30, Validation Loss: 0.4636439366473092\n",
      "Epoch 12/30, Training Loss: 0.46722942212937585\n",
      "Epoch 12/30, Validation Loss: 0.4611469507217407\n",
      "Epoch 13/30, Training Loss: 0.4724789471693442\n",
      "Epoch 13/30, Validation Loss: 0.44789876374933457\n",
      "Epoch 14/30, Training Loss: 0.4661383809338153\n",
      "Epoch 14/30, Validation Loss: 0.5489285770389769\n",
      "Epoch 15/30, Training Loss: 0.46770710970314455\n",
      "Epoch 15/30, Validation Loss: 0.4471589922904968\n",
      "Epoch 16/30, Training Loss: 0.4570165981709118\n",
      "Epoch 16/30, Validation Loss: 0.5156393001476923\n",
      "Epoch 17/30, Training Loss: 0.45506313485159\n",
      "Epoch 17/30, Validation Loss: 0.49720818135473466\n",
      "Epoch 18/30, Training Loss: 0.45272214102073455\n",
      "Epoch 18/30, Validation Loss: 0.46195242636733586\n",
      "Epoch 19/30, Training Loss: 0.44108560219616955\n",
      "Epoch 19/30, Validation Loss: 0.4723408536778556\n",
      "Epoch 20/30, Training Loss: 0.45351715532826703\n",
      "Epoch 20/30, Validation Loss: 0.43000900910960305\n",
      "Epoch 21/30, Training Loss: 0.4480556686159591\n",
      "Epoch 21/30, Validation Loss: 0.4433601780070199\n",
      "Epoch 22/30, Training Loss: 0.44378224057211\n",
      "Epoch 22/30, Validation Loss: 0.4466387894418504\n",
      "Epoch 23/30, Training Loss: 0.43474920073025664\n",
      "Epoch 23/30, Validation Loss: 0.43189477258258396\n",
      "Epoch 24/30, Training Loss: 0.4297100381112435\n",
      "Epoch 24/30, Validation Loss: 0.448907549182574\n",
      "Epoch 25/30, Training Loss: 0.43639573580782176\n",
      "Epoch 25/30, Validation Loss: 0.436176555024253\n",
      "Epoch 26/30, Training Loss: 0.4379440029742013\n",
      "Epoch 26/30, Validation Loss: 0.5589012404282888\n",
      "Epoch 27/30, Training Loss: 0.4285667290989782\n",
      "Epoch 27/30, Validation Loss: 0.42162085076173145\n",
      "Epoch 28/30, Training Loss: 0.4285078833640461\n",
      "Epoch 28/30, Validation Loss: 0.4445253362258275\n",
      "Epoch 29/30, Training Loss: 0.43202367215089393\n",
      "Epoch 29/30, Validation Loss: 0.46850279801421696\n",
      "Epoch 30/30, Training Loss: 0.4227564586719996\n",
      "Epoch 30/30, Validation Loss: 0.46514570381906295\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7561619718309859\n",
      "ROC AUC: 0.7440323262241071\n"
     ]
    }
   ],
   "source": [
    "# pytorch neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Convert data to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    # Set the device to MPS\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS not available, using CPU\")\n",
    "\n",
    "\n",
    "# Create a neural network class for binary classification\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)  # Increase the number of neurons\n",
    "        self.bn1 = nn.BatchNorm1d(64)  # Adjust to match the number of neurons\n",
    "        self.dropout1 = nn.Dropout(0.3)  # Increase the dropout rate\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.bn3 = nn.BatchNorm1d(16)  # Add a new layer\n",
    "        self.dropout3 = nn.Dropout(0.3)  # Add a new layer\n",
    "        self.fc4 = nn.Linear(16, 1)  # Add a new layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))  # Add a new layer\n",
    "        x = self.dropout3(x)  # Add a new layer\n",
    "        x = torch.sigmoid(self.fc4(x))  # Adjust to use the new layer\n",
    "        return x\n",
    "        \n",
    "    \n",
    "# Create an instance of the neural network\n",
    "input_dim = X_train.shape[1]\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "model = NeuralNetwork(input_dim)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "# Send the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 30\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Training Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    average_training_loss = running_loss / len(train_loader)\n",
    "    training_losses.append(average_training_loss)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            inputs, labels = data\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1))\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Validation Loss: {val_loss/len(test_loader)}\")\n",
    "\n",
    "    average_validation_loss = val_loss / len(test_loader)\n",
    "    validation_losses.append(average_validation_loss)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.plot(validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "y_pred = model(X_test_tensor.to(device)).detach().cpu().numpy()\n",
    "\n",
    "# Convert the predictions to binary\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "\n",
    "\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1313393584.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    ROC AUC: 0.6184690294279336\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Accuracy: 0.8257042253521126\n",
    "ROC AUC: 0.7334619800373225\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing\n",
    "\n",
    "Train, validate and test your model. Comment on the performance metrics. Note the best-performing model on the [MatBench](https://matbench.materialsproject.org) leaderboard.  With limited resources, don't expect to match this performance, but you should do better than a baseline model. \n",
    "\n",
    "<details>\n",
    "<summary>Note on the ROC-AUC classification metric</summary>\n",
    "There is one metric we didn't cover but is used in Matbench. In binary classification models, the ROC-AUC (Receiver Operating Characteristic - Area Under the Curve) score can be used to evaluate performance. It quantifies the ability of the model to distinguish between positive and negative instances across different decision thresholds. A higher ROC-AUC score (ranging from 0.5 to 1) indicates better performance, with 1 representing a perfect classifier and 0.5 indicating performance no better than random chance. There is a more detailed discussion on https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc.\n",
    "\n",
    "The metric can be calculated using the `roc_auc_score` function from the `sklearn.metrics` module, e.g.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Assuming you have true labels (y_true) and predicted probabilities (y_pred_prob) \n",
    "y_true = [...]  \n",
    "y_pred_prob = [...]  \n",
    "\n",
    "# Calculate ROC-AUC\n",
    "roc_auc = roc_auc_score(y_true, y_pred_prob)\n",
    "\n",
    "# Display the result\n",
    "print(f'ROC-AUC Score: {roc_auc:.4f}')\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spare cell\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Language Model (LLM) usage declaration\n",
    "\n",
    "You should acknowledge any use of a generative model during your assignment. Points to consider:\n",
    "\n",
    "* State which LLM (e.g. GPT-3, Gemini, Co-Pilot)\n",
    "\n",
    "* Specify tasks (e.g. summarising research or code snippets)\n",
    "\n",
    "* Were any limitations/biases noted?\n",
    "\n",
    "* How did you ensure ethical use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spare cell\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚òòÔ∏è Final word\n",
    "\n",
    "Good luck building your own model! I hope that you enjoyed the course and exercises. Dive deeper into the aspects that caught your interest. A useful starting point may be the [Resources](https://aronwalsh.github.io/MLforMaterials/Resources.html) page. \n",
    "\n",
    "Remember that submission is on Blackboard and this time you should upload the actual Juypter Notebook (`.ipynb` file), as well as your recorded narrated presentation (maximum 5 minutes; see guides on using [Zoom](https://www.youtube.com/watch?v=H9qhoAIzW3E) or [Powerpoint](https://www.youtube.com/watch?v=Y5dgwwa5XRA) for this purpose)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
